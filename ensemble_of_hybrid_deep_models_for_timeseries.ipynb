{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W71I_JqTu29i"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import regularizers\n",
        "from keras.layers import Dense, Dropout, Flatten, LSTM, Conv1D, MaxPool2D, BatchNormalization, Activation, GlobalAveragePooling1D\n",
        "from keras.optimizers import Adam\n",
        "from scipy import stats\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDm_agE50hAd"
      },
      "outputs": [],
      "source": [
        "def hybridDeepModel():\n",
        "  nb_classes=7\n",
        "\n",
        "  #First sub model\n",
        "  input_layer0 = keras.layers.Input((90,9))\n",
        "\n",
        "  # BLOCK 1\n",
        "  conv_x0 = Conv1D(filters=n_feature_maps, kernel_size=8, padding='same')(input_layer0)\n",
        "  conv_x0 = BatchNormalization()(conv_x0)\n",
        "  conv_x0 = Activation('relu')(conv_x0)\n",
        "\n",
        "  conv_y0 = Conv1D(filters=n_feature_maps, kernel_size=5, padding='same')(conv_x0)\n",
        "  conv_y0 = BatchNormalization()(conv_y0)\n",
        "  conv_y0 = Activation('relu')(conv_y0)\n",
        "\n",
        "  conv_z0 = Conv1D(filters=n_feature_maps, kernel_size=3, padding='same')(conv_y0)\n",
        "  conv_z0 = BatchNormalization()(conv_z0)\n",
        "\n",
        "  # expand channels for the sum\n",
        "  shortcut_y0 = Conv1D(filters=n_feature_maps, kernel_size=1, padding='same')(input_layer0)\n",
        "  shortcut_y0 = BatchNormalization()(shortcut_y0)\n",
        "\n",
        "  output_block_10 = keras.layers.add([shortcut_y0, conv_z0])\n",
        "  output_block_10 = Activation('relu')(output_block_10)\n",
        "\n",
        "  # BLOCK 2\n",
        "  conv_x0 = Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(output_block_10)\n",
        "  conv_x0 = BatchNormalization()(conv_x0)\n",
        "  conv_x0 = Activation('relu')(conv_x0)\n",
        "\n",
        "  conv_y0 = Conv1D(filters=n_feature_maps * 2, kernel_size=5, padding='same')(conv_x0)\n",
        "  conv_y0 = BatchNormalization()(conv_y0)\n",
        "  conv_y0 = Activation('relu')(conv_y0)\n",
        "\n",
        "  conv_z0 = Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_y0)\n",
        "  conv_z0 = BatchNormalization()(conv_z0)\n",
        "\n",
        "  # expand channels for the sum\n",
        "  shortcut_y0 = Conv1D(filters=n_feature_maps * 2, kernel_size=1, padding='same')(output_block_10)\n",
        "  shortcut_y0 = BatchNormalization()(shortcut_y0)\n",
        "\n",
        "  output_block_20 = keras.layers.add([shortcut_y0, conv_z0])\n",
        "  output_block_20 = Activation('relu')(output_block_20)\n",
        "\n",
        "  # BLOCK 3\n",
        "  conv_x0 = Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(output_block_20)\n",
        "  conv_x0 = BatchNormalization()(conv_x0)\n",
        "  conv_x0 = Activation('relu')(conv_x0)\n",
        "\n",
        "  conv_y0 = Conv1D(filters=n_feature_maps * 2, kernel_size=5, padding='same')(conv_x0)\n",
        "  conv_y0 = BatchNormalization()(conv_y0)\n",
        "  conv_y0 = Activation('relu')(conv_y0)\n",
        "\n",
        "  conv_z0 = Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_y0)\n",
        "  conv_z0 = BatchNormalization()(conv_z0)\n",
        "\n",
        "  shortcut_y0 = BatchNormalization()(output_block_20)\n",
        "  output_block_30 = keras.layers.add([shortcut_y0, conv_z0])\n",
        "  output_block_30 = Activation('relu')(output_block_30)\n",
        "\n",
        "  gap_layer0 = GlobalAveragePooling1D()(output_block_30)\n",
        "  output_layer0 = Dense(512,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),  activation='relu')(gap_layer0)\n",
        "\n",
        "  #Second sub model\n",
        "  input_layer1=keras.layers.Input(shape=(90,9))\n",
        "  conv11 = Conv1D(256,kernel_size=7,kernel_initializer=\"he_normal\", activation='relu')(input_layer1)\n",
        "  bn1=BatchNormalization()(conv11)\n",
        "  maxpool1=MaxPool1D(5)(bn1)\n",
        "  conv21=Conv1D(128, kernel_size=5, kernel_initializer=\"he_normal\",activation='relu')(maxpool1)\n",
        "  maxpool21=MaxPool1D(5)(conv21)\n",
        "  drop1=Dropout(rate=0.5)(maxpool21)\n",
        "  flat1=Flatten()(drop1)\n",
        "  output_layer1= Dense(units=128,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4), activation='relu')(flat1)\n",
        "\n",
        "\n",
        "  #Third sub model\n",
        "  input_layer2=keras.layers.Input(shape=(90,9))\n",
        "  conv21=Conv1D(filters=64,kernel_size=5,padding=\"same\", kernel_initializer=\"he_normal\", activation='relu')(input_layer2)\n",
        "  conv22=Conv1D(filters=64,kernel_size=3,padding=\"same\", activation=\"relu\")(conv21)\n",
        "  pool21=keras.layers.MaxPool1D(pool_size=2,strides=2)(conv22)\n",
        "  conv23=Conv1D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\")(pool21)\n",
        "  conv24=Conv1D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\")(conv23)\n",
        "  pool22=keras.layers.MaxPool1D(pool_size=2,strides=2)(conv24)\n",
        "  conv25=Conv1D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\")(pool22)\n",
        "  conv26=Conv1D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\")(conv25)\n",
        "  conv27=Conv1D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\")(conv26)\n",
        "  pool23=keras.layers.MaxPool1D(pool_size=2,strides=2)(conv27)\n",
        "  conv28=Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\")(pool23)\n",
        "  conv29=Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\")(conv28)\n",
        "  conv210=Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\")(conv29)\n",
        "  pool24=keras.layers.MaxPool1D(pool_size=2,strides=2)(conv210)\n",
        "  conv211=Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\")(pool24)\n",
        "  conv212=Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\")(conv211)\n",
        "  conv213=Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\")(conv212)\n",
        "  pool25=MaxPool1D(pool_size=2,strides=2)(conv213)\n",
        "  flat2=Flatten()(pool25)\n",
        "  dense21=Dense(units=1024,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),activation=\"relu\")(flat2)\n",
        "  output_layer2=Dense(units=512,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),activation=\"relu\")(dense21)\n",
        "\n",
        "\n",
        "  #Forth sub model\n",
        "  input_layer3 = keras.layers.Input(shape=(90,9))\n",
        "  conv31 = Conv1D(256,kernel_size=7,kernel_initializer=\"he_normal\", activation='relu')(input_layer3)\n",
        "  bn3 = BatchNormalization()(conv31)\n",
        "  maxpool3 = MaxPool1D(5)(bn3)\n",
        "  conv31 = Conv1D(128, kernel_size=5, kernel_initializer=\"he_normal\",activation='relu')(maxpool3)\n",
        "  maxpool31 = MaxPool1D(5)(conv31)\n",
        "  drop3 = Dropout(rate=0.7)(maxpool31)\n",
        "  lstm3 = LSTM(100)(drop3)\n",
        "  output_layer3 = Dense(units=128,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4), activation='relu')(lstm3)\n",
        "\n",
        "  concatted = keras.layers.Concatenate()([output_layer0, output_layer1, output_layer2,output_layer3])\n",
        "  output_layer = keras.layers.Dense(nb_classes,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),  activation='softmax')(concatted)\n",
        "  model = keras.models.Model(inputs=[input_layer0,input_layer1,input_layer2,input_layer3], outputs=output_layer)\n",
        "  opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "  model.compile(loss='logcosh', optimizer=opt, metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwCnokBC0Z1E"
      },
      "outputs": [],
      "source": [
        "nb_model=4\n",
        "model=[0]*nb_model\n",
        "for i in range(nb_model):\n",
        "  model[i]=hybridDeepModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAdTGvs0Jhe-"
      },
      "outputs": [],
      "source": [
        "reduce_learning_rate = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                                         factor=0.5,\n",
        "                                         patience=4,\n",
        "                                         verbose=1,\n",
        "                                         epsilon=0.001,\n",
        "                                         cooldown=0,\n",
        "                                         min_lr=0.0000001)\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=16, restore_best_weights=True)\n",
        "\n",
        "#Laod and cancat train sets\n",
        "train_x[0]=np.concatenate((train_no_aug_raw,train_no_aug_20hz,train_no_aug_25hz,train_no_aug_40hz,train_no_aug_50hz),axis=0)\n",
        "train_x[1]=np.concatenate((train_jit_raw,train_jit_20hz,train_jit_25hz,train_jit_40hz,train_jit_50hz),axis=0)\n",
        "train_x[2]=np.concatenate((train_perm_raw,train_perm_20hz,train_perm_25hz,train_perm_40hz,train_perm_50hz),axis=0)\n",
        "train_x[3]=np.concatenate((train_mag_raw,train_mag_20hz,train_mag_25hz,train_mag_40hz,train_mag_50hz),axis=0)\n",
        "#jit --> jittering  mag--> magnitude warping  perm --> permutation\n",
        "\n",
        "#train models\n",
        "model[0].fit(x=[train_x[0],train_x[1],train_x[2],train_x[3]], y=train_y, epochs=300, validation_split=0.2, batch_size=128, shuffle=True, callbacks=[reduce_learning_rate,early_stopping,model_checkpoint_callback])\n",
        "model[1].fit(x=[train_x[3],train_x[0],train_x[1],train_x[2]], y=train_y, epochs=300, validation_split=0.2, batch_size=128, shuffle=True, callbacks=[reduce_learning_rate,early_stopping,model_checkpoint_callback])\n",
        "model[2].fit(x=[train_x[1],train_x[2],train_x[3],train_x[0]], y=train_y, epochs=300, validation_split=0.2, batch_size=128, shuffle=True, callbacks=[reduce_learning_rate,early_stopping,model_checkpoint_callback])\n",
        "model[3].fit(x=[train_x[2],train_x[3],train_x[0],train_x[1]], y=train_y, epochs=300, validation_split=0.2, batch_size=128, shuffle=True, callbacks=[reduce_learning_rate,early_stopping,model_checkpoint_callback])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lab_pred=[0]*nb_model\n",
        "y_pred=[0]*nb_model\n",
        "\n",
        "for i in range(nb_model):\n",
        "  y_pred[i]=model[i].predict([test_x,test_x,test_x,test_x])\n",
        "  lab_pred[i]=np.argmax(y_pred[i],axis=1)\n",
        "labtest=np.argmax(test_y,axis=1)"
      ],
      "metadata": {
        "id": "fmIgUrT2gha9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate accuracy of Ensemble of Hybrid Deep Models\n",
        "count=0\n",
        "for i in range(nb_test):\n",
        "  if labtest[i]==stats.mode(lab_pred[:,i])[0]:\n",
        "    count+=1\n",
        "ens_acc=count/nb_test"
      ],
      "metadata": {
        "id": "66LJ4XLai4Z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate accuracy of weighted Ensemble of Hybrid Deep Models\n",
        "probablities=1.1*(y_pred[0])+y_pred[1]+1.1*(y_pred[2])+y_pred[3]\n",
        "argmax=np.argmax(probablities,axis=1)\n",
        "wens_acc=np.sum(labtest == argmax)/nb_test"
      ],
      "metadata": {
        "id": "eRzWbr2coN5p"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
